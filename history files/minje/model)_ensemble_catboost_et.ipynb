{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soft Voting with et_400 and catboost_300\n",
    "\n",
    "1. 데이터  \n",
    "    * data_0119 사용함  \n",
    "    * label encoding  \n",
    "#\n",
    "2. Ensemble  \n",
    "    * et_400으로 Modeling하고 prediction을 도출함\n",
    "    * catboost_300으로 Modeling하고 predicion을 도출함\n",
    "    * prediction에 대한 proba를 비교하여 더 높은 예측값을 채택함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 import & 데이터 로딩 & 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.seed = 42\n",
    "DATA_PATH = \"../data_0119/\"\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "PATH_2017 = DATA_PATH + \"train/KNOW_2017.csv\"\n",
    "PATH_2018 = DATA_PATH + \"train/KNOW_2018.csv\"\n",
    "PATH_2019 = DATA_PATH + \"train/KNOW_2019.csv\"\n",
    "PATH_2020 = DATA_PATH + \"train/KNOW_2020.csv\"\n",
    "\n",
    "paths = [PATH_2017, PATH_2018, PATH_2019, PATH_2020]\n",
    "know_train = [pd.read_csv(path) for path in paths]\n",
    "\n",
    "TEST_PATH_2017 = DATA_PATH + \"test/KNOW_2017_test.csv\"\n",
    "TEST_PATH_2018 = DATA_PATH + \"test/KNOW_2018_test.csv\"\n",
    "TEST_PATH_2019 = DATA_PATH + \"test/KNOW_2019_test.csv\"\n",
    "TEST_PATH_2020 = DATA_PATH + \"test/KNOW_2020_test.csv\"\n",
    "\n",
    "TEST_PATHs = [TEST_PATH_2017, TEST_PATH_2018, TEST_PATH_2019, TEST_PATH_2020]\n",
    "know_test = [pd.read_csv(path) for path in TEST_PATHs]\n",
    "\n",
    "years = ['2017', '2018', '2019', '2020']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "years = ['2017', '2018', '2019', '2020']\n",
    "\n",
    "year_encoder = {}\n",
    "\n",
    "for year, df in zip(years, know_train):\n",
    "    print(year)\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == 'idx':\n",
    "            print(\"HEHE\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            df[col] = df[col].map(int)\n",
    "        except:\n",
    "            encoder = LabelEncoder()\n",
    "            df[col] = df[col].map(str)\n",
    "            df[col] = encoder.fit_transform(df[col])\n",
    "            encoders[col] = encoder\n",
    "            \n",
    "            \n",
    "    year_encoder[year] = encoders\n",
    "\n",
    "# encode test data\n",
    "years = ['2017', '2018', '2019', '2020']\n",
    "\n",
    "for year, df in zip(years, know_test):\n",
    "    print(year)\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        try:\n",
    "            df[col] = df[col].map(int)\n",
    "        except:\n",
    "            encoder = year_encoder[year][col]\n",
    "            df[col] = df[col].map(str)\n",
    "            category_map = {category: idx for idx, category in enumerate(encoder.classes_)}\n",
    "            df[col] = df[col].apply(lambda x: category_map[x] if x in category_map else -1) # train set에서 보지못한 카테고리변수 -1(UNK) 처리\n",
    "\n",
    "train_data = {}\n",
    "for year, df in zip(years, know_train):\n",
    "    train_data[year] = {'X': df.drop(['idx','knowcode','description'], axis=1),\n",
    "                        'y': df['knowcode']}\n",
    "\n",
    "test_data = {}\n",
    "for year, df in zip(years, know_test):\n",
    "    print(year)\n",
    "    train_columns = train_data[year]['X'].columns\n",
    "    test_data[year] =  {'X': df[train_columns]} \n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    print(f\"train: {train_data[year]['X'].shape} test: {test_data[year]['X'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "et modeling...\n",
      "et prediction...\n",
      "cat modeling...\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.0246571\ttotal: 11.6s\tremaining: 11.6s\n",
      "1:\tlearn: 0.0305460\ttotal: 23s\tremaining: 0us\n",
      "cat prediction...\n",
      "et modeling...\n",
      "et prediction...\n",
      "cat modeling...\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.0131363\ttotal: 10.6s\tremaining: 10.6s\n",
      "1:\tlearn: 0.0259929\ttotal: 20.9s\tremaining: 0us\n",
      "cat prediction...\n",
      "et modeling...\n",
      "et prediction...\n",
      "cat modeling...\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.0083804\ttotal: 10.8s\tremaining: 10.8s\n",
      "1:\tlearn: 0.0305945\ttotal: 22s\tremaining: 0us\n",
      "cat prediction...\n",
      "et modeling...\n",
      "et prediction...\n",
      "cat modeling...\n",
      "Learning rate set to 0.5\n",
      "0:\tlearn: 0.0101639\ttotal: 10s\tremaining: 10s\n",
      "1:\tlearn: 0.0209163\ttotal: 20.1s\tremaining: 0us\n",
      "cat prediction...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "ensemble_preds = []\n",
    "for year in years:\n",
    "    print(year)\n",
    "    #####################################################################################################\n",
    "    print(' et modeling...')\n",
    "    model = ExtraTreesClassifier(n_estimators=400, random_state=RANDOM_STATE, n_jobs=8)\n",
    "    model.fit(train_data[year]['X'].iloc[:, :], train_data[year]['y'])\n",
    "\n",
    "    print(' et prediction...')\n",
    "    # 예측하기\n",
    "    et_prob_df = pd.DataFrame(model.predict_proba(test_data[year]['X']), columns=model.classes_)\n",
    "\n",
    "    # prop 구하기\n",
    "    et_result_prob = list(et_prob_df.apply(lambda x: x.max(),axis=1))\n",
    "\n",
    "    # class 구하기\n",
    "    et_result_class = []\n",
    "    for index in range(test_data[year]['X'].shape[0]):\n",
    "        et_prop_index_series = et_prob_df.loc[index,:]\n",
    "        et_class = list(et_prop_index_series.loc[et_prop_index_series==et_result_prob[index]].index)[0]\n",
    "        et_result_class.append(et_class)\n",
    "\n",
    "    # result 내기\n",
    "    et_results_df = pd.DataFrame(index=range(test_data[year]['X'].shape[0]))\n",
    "    et_results_df['prop'] = et_result_prob\n",
    "    et_results_df['label'] = et_result_class\n",
    "\n",
    "    #####################################################################################################\n",
    "    \n",
    "    print(' cat modeling...')\n",
    "    model = CatBoostClassifier(iterations=300,\n",
    "                            random_state=RANDOM_STATE,\n",
    "                            task_type='GPU',\n",
    "                            loss_function='MultiClass',\n",
    "                            eval_metric='TotalF1'\n",
    "                            )\n",
    "    model.fit(train_data[year]['X'].iloc[:, :], train_data[year]['y'])\n",
    "\n",
    "    print(' cat prediction...')\n",
    "    # 예측하기\n",
    "    cat_prob_df = pd.DataFrame(model.predict_proba(test_data[year]['X']), columns=model.classes_)\n",
    "\n",
    "    # prop 구하기\n",
    "    cat_result_prob = list(cat_prob_df.apply(lambda x: x.max(),axis=1))\n",
    "\n",
    "    # class 구하기\n",
    "    cat_result_class = []\n",
    "    for index in range(test_data[year]['X'].shape[0]):\n",
    "        cat_prop_index_series = cat_prob_df.loc[index,:]\n",
    "        cat_class = list(cat_prop_index_series.loc[cat_prop_index_series==cat_result_prob[index]].index)[0]\n",
    "        cat_result_class.append(cat_class)\n",
    "\n",
    "    # result 내기\n",
    "    cat_results_df = pd.DataFrame(index=range(test_data[year]['X'].shape[0]))\n",
    "    cat_results_df['prop'] = cat_result_prob\n",
    "    cat_results_df['label'] = cat_result_class\n",
    "    #####################################################################################################\n",
    "    year_pred = []\n",
    "    for index, (et_prop, cat_prop) in enumerate(zip(et_results_df['prop'], cat_results_df['prop'])):\n",
    "        if et_prop <= cat_prop:\n",
    "            year_pred.append(cat_results_df.loc[index,'label'])\n",
    "        else:\n",
    "            year_pred.append(et_results_df.loc[index,'label'])\n",
    "    \n",
    "    ensemble_preds.extend(year_pred)\n",
    "    print('##'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data_0103/sample_submission.csv') # sample submission 불러오기\n",
    "submission['knowcode'] = ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('../submission_files/et_400_with_data_0119_dropcols.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
