{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Test 데이터 불러오기\n",
    "\n",
    "각 년도별 DataFrame을 리스트에 append합니다.\n",
    "\n",
    "리스트 인덱스별로\n",
    "\n",
    "0: 2017년도 데이터   \n",
    "\n",
    "1: 2018년도 데이터 \n",
    "\n",
    "2: 2019년도 데이터 \n",
    "\n",
    "3: 202년도 데이터 \n",
    "\n",
    "입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.seed = 42\n",
    "DATA_PATH = \"../data_0119/\"\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "PATH_2017 = DATA_PATH + \"train/KNOW_2017.csv\"\n",
    "PATH_2018 = DATA_PATH + \"train/KNOW_2018.csv\"\n",
    "PATH_2019 = DATA_PATH + \"train/KNOW_2019.csv\"\n",
    "PATH_2020 = DATA_PATH + \"train/KNOW_2020.csv\"\n",
    "\n",
    "paths = [PATH_2017, PATH_2018, PATH_2019, PATH_2020]\n",
    "know_train = [pd.read_csv(path) for path in paths]\n",
    "\n",
    "TEST_PATH_2017 = DATA_PATH + \"test/KNOW_2017_test.csv\"\n",
    "TEST_PATH_2018 = DATA_PATH + \"test/KNOW_2018_test.csv\"\n",
    "TEST_PATH_2019 = DATA_PATH + \"test/KNOW_2019_test.csv\"\n",
    "TEST_PATH_2020 = DATA_PATH + \"test/KNOW_2020_test.csv\"\n",
    "\n",
    "TEST_PATHs = [TEST_PATH_2017, TEST_PATH_2018, TEST_PATH_2019, TEST_PATH_2020]\n",
    "know_test = [pd.read_csv(path) for path in TEST_PATHs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_cols_2017 = ['aq1_2', 'aq2_2', 'aq3_2', 'aq4_2', 'aq5_2', 'aq6_2', 'aq7_2', 'aq8_2', 'aq9_2', 'aq10_2'\n",
    "                ,'aq11_2', 'aq12_2', 'aq13_2', 'aq14_2', 'aq15_2', 'aq16_2', 'aq17_2', 'aq18_2', 'aq19_2', 'aq20_2'\n",
    "                ,'aq21_2', 'aq22_2', 'aq23_2', 'aq24_2', 'aq25_2', 'aq26_2', 'aq27_2', 'aq28_2', 'aq29_2', 'aq30_2'\n",
    "                ,'aq31_2', 'aq32_2', 'aq33_2', 'aq34_2', 'aq35_2', 'aq36_2', 'aq37_2', 'aq38_2', 'aq39_2', 'aq40_2'\n",
    "                ,'aq41_2']  \n",
    "skip_cols_2018 = []  \n",
    "skip_cols_2019 = ['kq1_2', 'kq2_2', 'kq3_2', 'kq4_2', 'kq5_2', 'kq6_2', 'kq7_2', 'kq8_2', 'kq9_2', 'kq10_2'\n",
    "            ,'kq11_2', 'kq12_2', 'kq13_2', 'kq14_2', 'kq15_2','kq16_2', 'kq17_2', 'kq18_2', 'kq19_2','kq20_2'\n",
    "            ,'kq21_2', 'kq22_2', 'kq23_2', 'kq24_2', 'kq25_2','kq26_2', 'kq27_2','kq28_2', 'kq29_2', 'kq30_2'\n",
    "            ,'kq31_2', 'kq32_2','kq33_2']\n",
    "skip_cols_2020 = ['saq1_2', 'saq2_2', 'saq3_2', 'saq4_2', 'saq5_2','saq6_2', 'saq7_2', 'saq8_2', 'saq9_2', 'saq10_2'\n",
    "                ,'saq11_2', 'saq12_2', 'saq13_2', 'saq14_2','saq15_2', 'saq16_2', 'saq17_2', 'saq18_2', 'saq19_2'\n",
    "                ,'saq20_2', 'saq21_2', 'saq22_2', 'saq23_2', 'saq24_2', 'saq25_2', 'saq26_2', 'saq27_2', 'saq28_2', 'saq29_2'\n",
    "                ,'saq30_2', 'saq31_2', 'saq32_2', 'saq33_2', 'saq34_2', 'saq35_2','saq36_2', 'saq37_2', 'saq38_2' \n",
    "                , 'saq39_2', 'saq40_2', 'saq41_2', 'saq42_2',  'saq43_2', 'saq44_2' \n",
    "                ]\n",
    "\n",
    "skip_cols_list =[skip_cols_2017, skip_cols_2018, skip_cols_2019, skip_cols_2020]\n",
    "\n",
    "for i, skip_cols in enumerate(skip_cols_list):\n",
    "    know_train[i] = know_train[i].drop(skip_cols,axis=1)\n",
    "    know_test[i] = know_test[i].drop(skip_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 \n",
    "\n",
    "`data_0119`는 이미 전처리된 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017: (9486, 230)\n",
      "2018: (9072, 241)\n",
      "2019: (8555, 218)\n",
      "2020: (8122, 246)\n"
     ]
    }
   ],
   "source": [
    "years = ['2017', '2018', '2019', '2020']\n",
    "for i in range(4):\n",
    "    print(f\"{2017+i}: {know_train[i].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라벨 인코딩\n",
    "\n",
    "숫자로 변환할 수 있는 컬럼은 라벨 인코딩을 사용하지 않았습니다.\n",
    "\n",
    "string이나 object컬럼은 라벨인코더를 이용해 변환하였으며 추후 test셋에 사용해야하기 때문에 년도별, 컬럼별로 dictionary를 이용해 저장하였습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "HEHE\n",
      "2018\n",
      "HEHE\n",
      "2019\n",
      "HEHE\n",
      "2020\n",
      "HEHE\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "years = ['2017', '2018', '2019', '2020']\n",
    "\n",
    "year_encoder = {}\n",
    "\n",
    "for year, df in zip(years, know_train):\n",
    "    print(year)\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == 'idx':\n",
    "            print(\"HEHE\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            df[col] = df[col].map(int)\n",
    "        except:\n",
    "            encoder = LabelEncoder()\n",
    "            df[col] = df[col].map(str)\n",
    "            df[col] = encoder.fit_transform(df[col])\n",
    "            encoders[col] = encoder\n",
    "            \n",
    "            \n",
    "    year_encoder[year] = encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "# encode test data\n",
    "years = ['2017', '2018', '2019', '2020']\n",
    "\n",
    "for year, df in zip(years, know_test):\n",
    "    print(year)\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        try:\n",
    "            df[col] = df[col].map(int)\n",
    "        except:\n",
    "            encoder = year_encoder[year][col]\n",
    "            df[col] = df[col].map(str)\n",
    "            category_map = {category: idx for idx, category in enumerate(encoder.classes_)}\n",
    "            df[col] = df[col].apply(lambda x: category_map[x] if x in category_map else -1) # train set에서 보지못한 카테고리변수 -1(UNK) 처리\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, y 구분 및 모델 학습\n",
    "\n",
    "이번 대회에서 맞춰야 할 값은 knowcode입니다.\n",
    "\n",
    "ID와 knowcode를 제외한 나머지 feature를 X, knowcode를 정답 y로 두어 모델을 학습하였습니다.\n",
    "\n",
    "베이스라인에서는 의사결정나무와 랜덤포레스트를 선정하였습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.drop(['idx','knowcode', 'description'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "for year, df in zip(years, know_train):\n",
    "    train_data[year] = {'X': df.drop(['idx','knowcode','description'], axis=1),\n",
    "                        'y': df['knowcode']}\n",
    "\n",
    "test_data = {}\n",
    "for year, df in zip(years, know_test):\n",
    "    print(year)\n",
    "    train_columns = train_data[year]['X'].columns\n",
    "    test_data[year] =  {'X': df[train_columns]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "train: (9486, 227) test: (9486, 227)\n",
      "2018\n",
      "train: (9072, 238) test: (9069, 238)\n",
      "2019\n",
      "train: (8555, 215) test: (8554, 215)\n",
      "2020\n",
      "train: (8122, 243) test: (8122, 243)\n"
     ]
    }
   ],
   "source": [
    "for year in years:\n",
    "    print(year)\n",
    "    print(f\"train: {train_data[year]['X'].shape} test: {test_data[year]['X'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra Trees Classifier\n",
    "\n",
    "`n_estimators = 300`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:12<00:00, 63.18s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "et_models = {}\n",
    "et_predicts = [] \n",
    "\n",
    "for year in tqdm(years):\n",
    "    # train\n",
    "    if year =='2017':\n",
    "        model = ExtraTreesClassifier(n_estimators=200, random_state=RANDOM_STATE, n_jobs=8)\n",
    "    else:\n",
    "        model = ExtraTreesClassifier(n_estimators=400, random_state=RANDOM_STATE, n_jobs=8)\n",
    "    model.fit(train_data[year]['X'].iloc[:, :], train_data[year]['y'])\n",
    "\n",
    "    # predict\n",
    "    pred = model.predict(test_data[year]['X'])\n",
    "    et_predicts.extend(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 제출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../data_0103/sample_submission.csv') # sample submission 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['knowcode'] = et_predicts\n",
    "\n",
    "submission.to_csv('../submission_files/et_400_with_data_0119_dropcols.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0013f6b8b877ceb5a87410fb2eb4381e03ef70741d03c75e6783c98d6b327580"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('dacon-know': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
