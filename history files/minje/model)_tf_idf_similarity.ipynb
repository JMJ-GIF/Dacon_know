{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf_idf_similarity MulitiClassifier Model\n",
    "\n",
    "1. 데이터  \n",
    "    * data_0112를 사용함  \n",
    "    * data_0105의 text_response를 추가함  \n",
    "# \n",
    "2. tf-idf similarity matrix \n",
    "    * STEP 1 : train set과 test set을 합쳐서 tf_idf_matrix를 구하고 서로의 simliarity matrix를 구함\n",
    "    * STEP 2 : test_set의 특정 레코드와 가장 비슷한 레코드를 train_set에서 찾고 그 레코드의 knowcode를 결과값으로 내놓기\n",
    "#          \n",
    "3. fitting & prediction\n",
    "    * STEP 1 : 각 연도의 전체 데이터를 바탕으로 et_100을 학습시킨다\n",
    "    * STEP 2 : threshold를 기준으로, 유사도가 그 보다 높은 레코드에 대해서만 similarity matrix로 예측을 진행함\n",
    "    * STEP 3 : threshold를 기준으로, 유사도가 그 보다 낮은 레코드에 대해서, et_100으로 예측을 진행함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 라이브러리 import & 데이터 로딩 & 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "warnings.filterwarnings(action='ignore') \n",
    "pd.options.display.max_columns=None\n",
    "\n",
    "know_train = [pd.read_csv(path) for path in sorted(glob('../data_0112/train/*.csv'))]\n",
    "know_test = [pd.read_csv(path) for path in sorted(glob('../data_0112/test/*.csv'))]\n",
    "\n",
    "other_train = [pd.read_csv(path) for path in sorted(glob('../data_0105/train/*.csv'))]\n",
    "other_test = [pd.read_csv(path) for path in sorted(glob('../data_0105/test/*.csv'))]\n",
    "\n",
    "for num in range(4):\n",
    "    know_train[num]['text_response'] = other_train[num]['text_response']\n",
    "    know_train[num]['major'] = other_train[num]['major']\n",
    "    know_test[num]['text_response'] = other_test[num]['text_response']\n",
    "    know_test[num]['major'] = other_test[num]['major']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf similarity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1 : 같은 연도인 train_set, test_set으로 sim_df 만들기\n",
    "# input\n",
    "def get_tf_idf_sim_mat(train_data, test_data):\n",
    "    '''\n",
    "    TRAIN SET과 TEST SET을 합치고 그에 대한 tf_idf_matrix를 도출한 후, similarity matrix를 구함\n",
    "    '''\n",
    "    total_nouns_list = []\n",
    "\n",
    "    doc_nouns_list_train = [doc for doc in (train_data['text_response'] +' '+ train_data['major'])]\n",
    "    doc_nouns_list_test = [doc for doc in (test_data['text_response'] +' '+ test_data['major'])]\n",
    "\n",
    "    total_nouns_list.extend(doc_nouns_list_train)\n",
    "    total_nouns_list.extend(doc_nouns_list_test)\n",
    "\n",
    "    stopwords = ['없다', '공란', '0']\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df=1,stop_words=stopwords)\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(total_nouns_list)\n",
    "    doc_nouns_similarities = (tfidf_matrix * tfidf_matrix.T)\n",
    "    sim_df = pd.DataFrame(doc_nouns_similarities.toarray())\n",
    "    \n",
    "    return sim_df\n",
    "\n",
    "# STEP 2 : test_set의 특정 레코드와 가장 비슷한 레코드를 train_set에서 찾고 그 레코드의 knowcode를 결과값으로 내놓기\n",
    "def sim_pred(idx, sim_df, threshold, train_data):\n",
    "    '''\n",
    "    test_set의 특정 레코드와 가장 비슷한 레코드를 train_set에서 찾고 그 레코드의 knowcode를 결과값으로 내놓기\n",
    "    '''\n",
    "    \n",
    "    train_len = train_data.shape[0]\n",
    "    \n",
    "    test_set_record = idx + train_len   # sim_df에서 test_set의 index를 계산\n",
    "    sim_rank_series = sim_df.loc[test_set_record].sort_values(ascending=False) \n",
    "    filtered_sim_rank_series = sim_rank_series.loc[sim_rank_series.index < train_len]  # test_set_record와 가장 비슷한 train_set_record를 계산\n",
    "\n",
    "    target_index = list(filtered_sim_rank_series.head(1).index)[0]\n",
    "    target_similarity = list(filtered_sim_rank_series.head(1).values)[0]\n",
    "\n",
    "    if target_similarity > threshold:   # 조건을 만족한다면 유사한 train_set의 knowcode와 같은 것으로 예측\n",
    "        pred = train_data.loc[target_index,'knowcode']\n",
    "        \n",
    "    else:   # 조건을 만족하지 않는다면 건너뛰었다는 의미로 0을 반환\n",
    "        pred = 0\n",
    "    \n",
    "    return pred\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fitting & prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:51<00:00, 12.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 : 각 연도의 전체 데이터를 바탕으로 et_100을 학습시킨다\n",
    "years = ['2017','2018','2019','2020']\n",
    "train_data = {}\n",
    "\n",
    "for year, df in zip(years, know_train):\n",
    "    train_data[year] = {'X': df.drop(['text_response','idx','major','knowcode'], axis=1),\n",
    "                        'y': df['knowcode']}\n",
    "    \n",
    "RANDOM_STATE = 42\n",
    "et_models = {}\n",
    "\n",
    "for year in tqdm(years):\n",
    "    model = ExtraTreesClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=8)\n",
    "    model.fit(train_data[year]['X'], train_data[year]['y'])\n",
    "    et_models[year] = model\n",
    "\n",
    "# test data 준비하기\n",
    "test_data = {}\n",
    "\n",
    "for year, df in zip(years, know_test):\n",
    "    train_columns = train_data[year]['X'].columns\n",
    "    test_data[year] =  {'X': df[train_columns]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [01:35, 23.87s/it]\n"
     ]
    }
   ],
   "source": [
    "# STEP2 : threshold를 기준으로, 유사도가 그 보다 높은 레코드에 대해서만 similarity matrix로 예측을 진행함\n",
    "\n",
    "sim_predicts = [] \n",
    "threshold = 0.5\n",
    "\n",
    "for year, num in tqdm(zip(years,range(4))):\n",
    "    sim_df = get_tf_idf_sim_mat(know_train[num], know_test[num])    # sim_df를 먼저 구해주고\n",
    "    sim_predict = []\n",
    "    \n",
    "    for idx in range(test_data[year]['X'].shape[0]):\n",
    "        pred = sim_pred(idx, sim_df, threshold, know_train[num])\n",
    "        sim_predict.append(pred)\n",
    "\n",
    "    sim_predicts.extend(sim_predict)\n",
    "    \n",
    "submission = pd.read_csv('../data_0103/sample_submission.csv') # sample submission 불러오기\n",
    "submission['knowcode'] = sim_predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# STEP3 : threshold를 기준으로, 유사도가 그 보다 낮은 레코드에 대해서, et_100으로 예측을 진행함\n",
    "\n",
    "non_sim_predicts = []\n",
    "idx_start = 0\n",
    "idx_end = 0\n",
    "\n",
    "final_submission = pd.DataFrame()\n",
    "for year in tqdm(years):\n",
    "    test_len = test_data[year]['X'].shape[0] - 1\n",
    "    idx_end = idx_start + test_len\n",
    "    submission_year = submission.loc[idx_start:idx_end,:].reset_index(drop=True)\n",
    "    idx_start = idx_start + test_len + 1\n",
    "    \n",
    "    zero_indice = submission_year[submission_year['knowcode']==0].index     # 이전 예측에서 0으로 지정했던 데이터의 인덱스\n",
    "    \n",
    "    test_data_zero = test_data[year]['X'].loc[zero_indice,:]    # 그것들만 따로 추려서 model에 넣어 예측해주고\n",
    "    pred = et_models[year].predict(test_data_zero)\n",
    "    \n",
    "    submission_year.loc[zero_indice,'knowcode'] = pred      # submission에 채워줍니다\n",
    "    final_submission = pd.concat([final_submission, submission_year])\n",
    "    \n",
    "final_submission = final_submission.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv('et_data0112_tf_idf_matrix_sim_ver3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
