{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.seed = 42\n",
    "DATA_PATH = \"../data_0115/\"\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "PATH_2017 = DATA_PATH + \"train/KNOW_2017.csv\"\n",
    "PATH_2018 = DATA_PATH + \"train/KNOW_2018.csv\"\n",
    "PATH_2019 = DATA_PATH + \"train/KNOW_2019.csv\"\n",
    "PATH_2020 = DATA_PATH + \"train/KNOW_2020.csv\"\n",
    "\n",
    "paths = [PATH_2017, PATH_2018, PATH_2019, PATH_2020]\n",
    "\n",
    "know_train = [pd.read_csv(path) for path in paths]\n",
    "\n",
    "TEST_PATH_2017 = DATA_PATH + \"test/KNOW_2017_test.csv\"\n",
    "TEST_PATH_2018 = DATA_PATH + \"test/KNOW_2018_test.csv\"\n",
    "TEST_PATH_2019 = DATA_PATH + \"test/KNOW_2019_test.csv\"\n",
    "TEST_PATH_2020 = DATA_PATH + \"test/KNOW_2020_test.csv\"\n",
    "\n",
    "TEST_PATHs = [TEST_PATH_2017, TEST_PATH_2018, TEST_PATH_2019, TEST_PATH_2020]\n",
    "\n",
    "know_test = [pd.read_csv(path) for path in TEST_PATHs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_info_cols = {\"2017\": ['sim_job','bef_job','able_job','major'],\n",
    "                  \"2018\": ['sim_job','bef_job','able_job','major'],\n",
    "                  \"2019\": ['bef_job','able_job','major'],\n",
    "                  \"2020\": ['major'],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "description_2017 = pd.read_csv('../data_pdf_description/pdf_description_2017.csv')\n",
    "description_2018 = pd.read_csv('../data_pdf_description/pdf_description_2018.csv')\n",
    "description_2019 = pd.read_csv('../data_pdf_description/pdf_description_2019.csv')\n",
    "description_2020 = pd.read_csv('../data_pdf_description/pdf_description_2020.csv')\n",
    "description_dfs = {\"2017\": description_2017,\n",
    "                  \"2018\": description_2018,\n",
    "                  \"2019\": description_2019,\n",
    "                  \"2020\": description_2020,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "\n",
    "for i, year in enumerate(years):\n",
    "    for text_info_col in text_info_cols[year]:\n",
    "        know_train[i].loc[know_train[i][text_info_col]=='없다', text_info_col] = ''\n",
    "        know_train[i].loc[know_train[i][text_info_col]=='없음', text_info_col] = ''\n",
    "        know_train[i].loc[know_train[i][text_info_col]=='0', text_info_col] = ''\n",
    "        know_train[i].loc[know_train[i][text_info_col]=='무', text_info_col] = ''\n",
    "        know_train[i].loc[know_train[i][text_info_col]=='모름', text_info_col] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jellyfish\n",
      "  Downloading jellyfish-0.9.0-cp38-cp38-win_amd64.whl (26 kB)\n",
      "Installing collected packages: jellyfish\n",
      "Successfully installed jellyfish-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install jellyfish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish\n",
    "from difflib import SequenceMatcher\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [\"2017\", \"2018\", \"2019\", \"2020\"]\n",
    "methods = {'SequenceMatcher':['knowcode_','similarity_'],\n",
    "           'levenshtein_distance':['knowcode_lev_','similarity_lev_'],\n",
    "           'damerau':['knowcode_dlev_','similarity_dlev_'],\n",
    "           'jaro_distance':['knowcode_jaro_','similarity_jaro_'],\n",
    "           'jaro_winkler':['knowcode_jarow_','similarity_jarow_'],\n",
    "           'hamming_distance':['knowcode_ham_','similarity_ham_']}\n",
    "\n",
    "def string_compare(know_data, text_info_cols, description_dfs, method):\n",
    "\n",
    "    data = know_data.copy()\n",
    "    \n",
    "    for i, year in enumerate(years):\n",
    "        # iterate 4 years\n",
    "        print(year)\n",
    "        for text_info_col in text_info_cols[year]:\n",
    "            print(text_info_col)\n",
    "            # iterate sim_job, bef_job, ...\n",
    "            text_info_list = list(data[i][text_info_col])\n",
    "        \n",
    "            knowcode_text_info_col = []\n",
    "            similarity_text_info_col = []\n",
    "\n",
    "            for possible_answer in tqdm(text_info_list):\n",
    "                # iterate each string in know_train[i][sim_job, bef_job, ...]\n",
    "                knowcode = \"0\"\n",
    "                similarity = 0.0\n",
    "                max_similarity_index = 0\n",
    "                for descr_row in description_dfs[year].itertuples():\n",
    "                    # iterate each row in description_dfs[year]\n",
    "                    if possible_answer != '':\n",
    "                        if method == 'SequenceMatcher':\n",
    "                            score = similar(possible_answer, descr_row.description)\n",
    "                        elif method == 'levenshtein_distance':\n",
    "                            score = jellyfish.levenshtein_distance(possible_answer, descr_row.description)\n",
    "                        elif method == 'damerau':\n",
    "                            score = jellyfish.damerau_levenshtein_distance(possible_answer, descr_row.description)\n",
    "                        elif method == 'jaro_distance':\n",
    "                            score = jellyfish.jaro_distance(possible_answer, descr_row.description)\n",
    "                        elif method == 'jaro_winkler':\n",
    "                            score = jellyfish.jaro_winkler(possible_answer, descr_row.description)\n",
    "                        elif method == 'hamming_distance':\n",
    "                            score = jellyfish.hamming_distance(possible_answer, descr_row.description)\n",
    "                        \n",
    "                        if score > similarity:\n",
    "                            similarity = score\n",
    "                            max_similarity_index = descr_row.Index\n",
    "                if similarity == 0:\n",
    "                    knowcode_text_info_col.append(\"0\")\n",
    "                else:\n",
    "                    knowcode_text_info_col.append(description_dfs[year].iloc[max_similarity_index, 0])\n",
    "                similarity_text_info_col.append(similarity)\n",
    "            data[i][methods[method][0] + text_info_col] = knowcode_text_info_col\n",
    "            data[i][methods[method][1] + text_info_col] = similarity_text_info_col\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6가지의 방법을 통해 결과를 구해봅시다\n",
    "# 한 시간정도 걸리네요(6가지 방법 x 4개 연도 = 24개의 df를 생성하는 것이니 꽤 걸려여)\n",
    "\n",
    "six_method_df_list = []\n",
    "for method in tqdm(methods.keys()):\n",
    "    data = string_compare(know_train, text_info_cols, description_dfs, method)\n",
    "    six_method_df_list.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 프레임에 각 연도별, 방법별 칼럼을 저장합니다\n",
    "# 중요한 모든 칼럼을 가지고 있음\n",
    "year_methods_df = pd.DataFrame(index=[years],columns=list(methods.keys()))\n",
    "\n",
    "for method in methods.keys():\n",
    "    for year in years:\n",
    "        value_list = []\n",
    "        text_cols = text_info_cols[year]\n",
    "        methods_cols = methods[method]\n",
    "        for text_col in text_cols:\n",
    "            for methods_col in methods_cols:\n",
    "                value_list.append(methods_col + text_col)\n",
    "        value_list.append('knowcode')\n",
    "        value_string = ''\n",
    "        for value in value_list:\n",
    "            value_string += value\n",
    "            value_string += ' '\n",
    "        year_methods_df.loc[year, method] = value_string[:-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 맞춘 개수를 연도별로, 방법별로 모아봅시다.\n",
    "Accuracy_dict = {}\n",
    "for method in methods.keys():\n",
    "    Accuracy_dict[method] = {}\n",
    "for method in methods.keys():\n",
    "    for year in years:\n",
    "       Accuracy_dict[method][year] = pd.DataFrame() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연도와 방법을 순회하면서 몇 개를 맞췄는지 비교해봅니다\n",
    "# Accuracy_dict에 결과를 담을것이고, Structure는 다음과 같습니다\n",
    "# method 선정 -> year 4개년도 순회 -> 각 연도별로 많이 맞춘 컬럼찾기\n",
    "# {method_1 : {year 1 : [dataFrame(cols = [text_info_cols], index = Accuracy)],\n",
    "#              year 2 : [dataFrame(cols = [text_info_cols], index = Accuracy)],\n",
    "#              year 3 : [dataFrame(cols = [text_info_cols], index = Accuracy)],\n",
    "#              year 4 : [dataFrame(cols = [text_info_cols], index = Accuracy)]}....}\n",
    "def get_best_method(df):\n",
    "    df_T = df.T\n",
    "    max_p = list(df_T.max())[0]\n",
    "    best_col = list(df_T[df_T['Accuracy']==max_p].index)[0]\n",
    "    return best_col\n",
    "\n",
    "for i, method in enumerate(methods.keys()):\n",
    "    data = six_method_df_list[i]\n",
    "    for k, year in enumerate(years):\n",
    "        accuracy_cols_string = list(year_methods_df.loc[year, method])[0] # 필요한 칼럼들을 가져옵니다\n",
    "        accuracy_cols = accuracy_cols_string.split(' ')\n",
    "        result_df = pd.DataFrame(index=['Accuracy'],columns=accuracy_cols) # 데이터 프레임 준비\n",
    "        \n",
    "        for col in accuracy_cols: # Accuracy 구하기\n",
    "            accuracy = data[k].loc[data[k]['knowcode']==data[k][col]].shape[0]\n",
    "            result_df[col] = accuracy\n",
    "        \n",
    "        result_df = result_df.drop('knowcode',axis=1)\n",
    "        best_col = get_best_method(result_df)\n",
    "        result_df['best_col'] = best_col\n",
    "        Accuracy_dict[method][year] = result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 요약 : 가장 성능이 좋았던 칼럼 찾기\n",
    "best_col_df = pd.DataFrame(index=[years],columns=list(methods.keys()))\n",
    "\n",
    "for year in years:\n",
    "    for method in methods:\n",
    "        best_col_df.loc[year,method] = list(Accuracy_dict[method][year]['best_col'])[0]\n",
    "        \n",
    "# 결과 요약 : 성능이 좋았던 칼럼이 맞춘 개수 찾기\n",
    "best_acc_df = pd.DataFrame(index=[years],columns=list(methods.keys()))\n",
    "\n",
    "for year in years:\n",
    "    for method in methods:\n",
    "        best_col = list(Accuracy_dict[method][year]['best_col'])[0]\n",
    "        best_acc_df.loc[year,method] = list(Accuracy_dict[method][year][best_col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SequenceMatcher</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>damerau</th>\n",
       "      <th>jaro_distance</th>\n",
       "      <th>jaro_winkler</th>\n",
       "      <th>hamming_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>knowcode_major</td>\n",
       "      <td>knowcode_lev_major</td>\n",
       "      <td>knowcode_dlev_major</td>\n",
       "      <td>knowcode_jaro_major</td>\n",
       "      <td>knowcode_jarow_major</td>\n",
       "      <td>knowcode_ham_major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>knowcode_major</td>\n",
       "      <td>knowcode_lev_sim_job</td>\n",
       "      <td>knowcode_dlev_sim_job</td>\n",
       "      <td>knowcode_jaro_major</td>\n",
       "      <td>knowcode_jarow_major</td>\n",
       "      <td>knowcode_ham_sim_job</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>knowcode_major</td>\n",
       "      <td>knowcode_lev_major</td>\n",
       "      <td>knowcode_dlev_major</td>\n",
       "      <td>knowcode_jaro_major</td>\n",
       "      <td>knowcode_jarow_major</td>\n",
       "      <td>knowcode_ham_major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>knowcode_major</td>\n",
       "      <td>knowcode_lev_major</td>\n",
       "      <td>knowcode_dlev_major</td>\n",
       "      <td>knowcode_jaro_major</td>\n",
       "      <td>knowcode_jarow_major</td>\n",
       "      <td>knowcode_ham_major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SequenceMatcher  levenshtein_distance                damerau  \\\n",
       "2017  knowcode_major    knowcode_lev_major    knowcode_dlev_major   \n",
       "2018  knowcode_major  knowcode_lev_sim_job  knowcode_dlev_sim_job   \n",
       "2019  knowcode_major    knowcode_lev_major    knowcode_dlev_major   \n",
       "2020  knowcode_major    knowcode_lev_major    knowcode_dlev_major   \n",
       "\n",
       "            jaro_distance          jaro_winkler      hamming_distance  \n",
       "2017  knowcode_jaro_major  knowcode_jarow_major    knowcode_ham_major  \n",
       "2018  knowcode_jaro_major  knowcode_jarow_major  knowcode_ham_sim_job  \n",
       "2019  knowcode_jaro_major  knowcode_jarow_major    knowcode_ham_major  \n",
       "2020  knowcode_jaro_major  knowcode_jarow_major    knowcode_ham_major  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_col_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SequenceMatcher</th>\n",
       "      <th>levenshtein_distance</th>\n",
       "      <th>damerau</th>\n",
       "      <th>jaro_distance</th>\n",
       "      <th>jaro_winkler</th>\n",
       "      <th>hamming_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017</th>\n",
       "      <td>692</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>689</td>\n",
       "      <td>696</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>724</td>\n",
       "      <td>705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>512</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>703</td>\n",
       "      <td>694</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>703</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>701</td>\n",
       "      <td>700</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SequenceMatcher levenshtein_distance damerau jaro_distance jaro_winkler  \\\n",
       "2017             692                    9       9           689          696   \n",
       "2018             524                    0       0           724          705   \n",
       "2019             512                   14      14           703          694   \n",
       "2020             703                   12      12           701          700   \n",
       "\n",
       "     hamming_distance  \n",
       "2017               15  \n",
       "2018                0  \n",
       "2019               15  \n",
       "2020               15  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_df"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6d46af94c2bbce495f1e668725902fa517c90b1782bcfe2fce0dd9868df553d3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
