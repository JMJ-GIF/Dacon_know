{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib import rc  \n",
    "rc('font', family='NanumGothic') \t\t\t\n",
    "plt.rcParams['axes.unicode_minus'] = False \n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "np.seed = 42\n",
    "DATA_PATH = \"../data_0103/\"\n",
    "\n",
    "PATH_2017 = DATA_PATH + \"train/KNOW_2017.csv\"\n",
    "PATH_2018 = DATA_PATH + \"train/KNOW_2018.csv\"\n",
    "PATH_2019 = DATA_PATH + \"train/KNOW_2019.csv\"\n",
    "PATH_2020 = DATA_PATH + \"train/KNOW_2020.csv\"\n",
    "\n",
    "paths = [PATH_2017, PATH_2018, PATH_2019, PATH_2020]\n",
    "\n",
    "know_train = [pd.read_csv(path) for path in paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "* baseline 모델과 동일하게 전처리\n",
    "    - 공백 '0'으로 대체\n",
    "    - object column은 라벨인코더를 이용해 변환\n",
    "    - 년도별, 컬럼별로 dictionary를 이용해 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in know_train:\n",
    "    for col in df.columns:\n",
    "        df[col].replace(' ', '0', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017\n",
      "HEY\n",
      "2018\n",
      "HEY\n",
      "2019\n",
      "HEY\n",
      "2020\n",
      "HEY\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "years = ['2017', '2018', '2019', '2020']\n",
    "\n",
    "year_encoder = {}\n",
    "\n",
    "for year, df in zip(years, know_train):\n",
    "    print(year)\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col == 'idx':\n",
    "            print(\"HEY\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            df[col] = df[col].map(int)\n",
    "        except:\n",
    "            encoder = LabelEncoder()\n",
    "            df[col] = df[col].map(str)\n",
    "            df[col] = encoder.fit_transform(df[col])\n",
    "            encoders[col] = encoder\n",
    "            \n",
    "            \n",
    "    year_encoder[year] = encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X, y 구분 및 모델 학습\n",
    "\n",
    "* random forest를 이용해 feature_importance 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {}\n",
    "for year, df in zip(years, know_train):\n",
    "    train_data[year] = {'X': df.iloc[:, 1:-1], # idx 제외\n",
    "                        'y': df.iloc[:, -1]} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X':       aq1_1  aq1_2  aq2_1  aq2_2  aq3_1  aq3_2  aq4_1  aq4_2  aq5_1  aq5_2  \\\n",
       " 0         3      3      3      3      3      3      4      4      3      4   \n",
       " 1         4      5      4      5      3      4      3      4      3      4   \n",
       " 2         3      4      3      4      3      4      5      6      4      5   \n",
       " 3         3      3      3      3      3      5      4      5      4      6   \n",
       " 4         4      5      3      4      3      4      4      5      3      4   \n",
       " ...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       " 9481      3      5      2      4      3      3      2      2      2      3   \n",
       " 9482      5      5      5      5      5      5      3      4      4      5   \n",
       " 9483      3      3      4      6      3      3      4      5      4      5   \n",
       " 9484      3      5      3      5      4      5      3      4      3      5   \n",
       " 9485      3      4      3      4      3      4      3      4      3      4   \n",
       " \n",
       "       ...  bq36  bq37  bq38  bq38_1  bq39_1  bq39_2  bq40  bq41_1  bq41_2  \\\n",
       " 0     ...     1    52     2     723       1       1     1    4000       0   \n",
       " 1     ...     1    38     4      33       1       1     1       0       0   \n",
       " 2     ...     1    50     4      33       1       1     1    4000       0   \n",
       " 3     ...     1    42     4    1446       1       1     1    7000       0   \n",
       " 4     ...     1    51     4      33       1       1     1    4000       0   \n",
       " ...   ...   ...   ...   ...     ...     ...     ...   ...     ...     ...   \n",
       " 9481  ...     1    50     4     543       1       1     1    5200       0   \n",
       " 9482  ...     1    37     4     862       1       1     1    4000       0   \n",
       " 9483  ...     1    32     2     216       1       4     2    2700       0   \n",
       " 9484  ...     2    40     4     384       1       1     1    6800       0   \n",
       " 9485  ...     1    48     3    1043       1       1     1    4000       0   \n",
       " \n",
       "       bq41_3  \n",
       " 0       2200  \n",
       " 1       2400  \n",
       " 2       2400  \n",
       " 3       3500  \n",
       " 4       2500  \n",
       " ...      ...  \n",
       " 9481    1800  \n",
       " 9482    3000  \n",
       " 9483    1500  \n",
       " 9484    2500  \n",
       " 9485    3700  \n",
       " \n",
       " [9486 rows x 154 columns],\n",
       " 'y': 0       825101\n",
       " 1       140204\n",
       " 2       140204\n",
       " 3       140601\n",
       " 4       140204\n",
       "          ...  \n",
       " 9481    411301\n",
       " 9482    151105\n",
       " 9483    701101\n",
       " 9484     25402\n",
       " 9485     15201\n",
       " Name: knowcode, Length: 9486, dtype: int64}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['2017']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:11<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_models = {}\n",
    "\n",
    "for year in tqdm(years):\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE, n_jobs=8)\n",
    "    model.fit(train_data[year]['X'].iloc[:, :], train_data[year]['y'])\n",
    "    rf_models[year] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017 top 10 ranking features\n",
      " 1. feature bq1     (0.0213)\n",
      " 2. feature bq38_1  (0.0185)\n",
      " 3. feature bq31    (0.0171)\n",
      " 4. feature bq41_3  (0.0162)\n",
      " 5. feature bq4_1a  (0.0159)\n",
      " 6. feature bq41_1  (0.0152)\n",
      " 7. feature bq19_1  (0.0141)\n",
      " 8. feature bq37    (0.0139)\n",
      " 9. feature bq3     (0.0111)\n",
      "10. feature bq2     (0.0103)\n",
      "------------------------------\n",
      "2018 top 10 ranking features\n",
      " 1. feature bq1     (0.0266)\n",
      " 2. feature bq37_1  (0.0202)\n",
      " 3. feature bq4_1a  (0.0201)\n",
      " 4. feature bq30    (0.0191)\n",
      " 5. feature bq36    (0.0175)\n",
      " 6. feature bq41_2  (0.0166)\n",
      " 7. feature bq41_1  (0.0163)\n",
      " 8. feature bq28_1  (0.0155)\n",
      " 9. feature bq40    (0.0154)\n",
      "10. feature bq3     (0.0131)\n",
      "------------------------------\n",
      "2019 top 10 ranking features\n",
      " 1. feature bq1     (0.0235)\n",
      " 2. feature bq4_1a  (0.0188)\n",
      " 3. feature bq27_1  (0.0178)\n",
      " 4. feature bq26    (0.0169)\n",
      " 5. feature bq31_2  (0.0151)\n",
      " 6. feature bq30    (0.0150)\n",
      " 7. feature bq31_1  (0.0145)\n",
      " 8. feature bq20_1  (0.0132)\n",
      " 9. feature bq3     (0.0116)\n",
      "10. feature bq6     (0.0105)\n",
      "------------------------------\n",
      "2020 top 10 ranking features\n",
      " 1. feature bq1     (0.0184)\n",
      " 2. feature bq4_1a  (0.0175)\n",
      " 3. feature bq26_1  (0.0166)\n",
      " 4. feature bq30_2  (0.0141)\n",
      " 5. feature bq20_1  (0.0130)\n",
      " 6. feature bq30_1  (0.0123)\n",
      " 7. feature bq25    (0.0118)\n",
      " 8. feature bq29    (0.0102)\n",
      " 9. feature bq3     (0.0086)\n",
      "10. feature bq7     (0.0084)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i, year in enumerate(years):\n",
    "    print(f\"{year} top 10 ranking features\")\n",
    "    importance = rf_models[year].feature_importances_\n",
    "    indices = np.argsort(importance)[::-1]\n",
    "\n",
    "    features = know_train[i].columns[1:-1]\n",
    "    for ix in range(10):\n",
    "        print(f\"{ix+1:2}. feature {features[indices][ix]:7} ({importance[indices][ix]:.4f})\")\n",
    "    \n",
    "    print(\"------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0013f6b8b877ceb5a87410fb2eb4381e03ef70741d03c75e6783c98d6b327580"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit ('dacon-know': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
